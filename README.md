# Spark-big-data-project-

در ابتدا با استفاده از اسکریپت doc2txt.py استفاده میکنیم تا فایل داکیومنت خود را به صورت text ذخیره کنیم.
در ادامه با استفاده از اسکریپت spark.py شروع به تحلیل فایل تکست میکنیم
در قسمت تبدیل به فایل تکست تمامی کاراکترهایی که به عنوان فضای خالی یا به اصطلاح white space اند را به اسپیس عادی تبدیل میکند
برای اینکه بتوان در بخش map کردن به صورت مستقیم از split استفاده کرد.

سپس در بخش spark به این شکل که تمامی کاکتر های اول کلمات در flatmap به عنوان ورودی و داده‌ای که برای تحلیل داده می‌شود قرار داده می‌شود.
و با فانکشن countByValue() تمامی آنها شمرده می‌شوند و مساله از شمردن کاراکتر‌های اول به شمردن کلمات یکسان تبدیل می‌شود.

![image](https://user-images.githubusercontent.com/47079265/144723860-230539d2-cb78-472a-94dd-72e757a4f921.png)

خروجی دفتر3 مثنوی با این روش را می‌توانید از عکس بالا ببینید.
